{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb163b7b",
   "metadata": {
    "id": "bb163b7b"
   },
   "source": [
    "Step 1. Ensure that you have the dataset file named `transactions.csv` in the current directory.\n",
    "\n",
    "The dataset is a subset of https://www.kaggle.com/ealaxi/paysim1/version/2 which was originally generated as part of the following research:\n",
    "\n",
    "E. A. Lopez-Rojas , A. Elmir, and S. Axelsson. \"PaySim: A financial mobile money simulator for fraud detection\". In: The 28th European Modeling and Simulation Symposium-EMSS, Larnaca, Cyprus. 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c898bd",
   "metadata": {
    "id": "72c898bd"
   },
   "source": [
    "Step 2. Complete the following exercises.\n",
    "\n",
    "0. Read the dataset (`transactions.csv`) as a Pandas dataframe. Note that the first row of the CSV contains the column names.\n",
    "\n",
    "0. Return the column names as a list from the dataframe.\n",
    "\n",
    "0. Return the first k rows from the dataframe.\n",
    "\n",
    "0. Return a random sample of k rows from the dataframe.\n",
    "\n",
    "0. Return a list of the unique transaction types.\n",
    "\n",
    "0. Return a Pandas series of the top 10 transaction destinations with frequencies.\n",
    "\n",
    "0. Return all the rows from the dataframe for which fraud was detected.\n",
    "\n",
    "0. Bonus. Return a dataframe that contains the number of distinct destinations that each source has interacted with to, sorted in descending order. You will find [groupby](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html) and [agg](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.groupby.DataFrameGroupBy.aggregate.html) useful. The predefined aggregate functions are under `pandas.core.groupby.GroupBy.*`. See the [left hand column](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.groupby.DataFrameGroupBy.nunique.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f146b9d",
   "metadata": {
    "id": "2f146b9d"
   },
   "source": [
    "Use the empty cell to test the exercises. If you modify the original `df`, you can rerun the cell containing `exercise_0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "EDd3m5pMN01e",
   "metadata": {
    "id": "EDd3m5pMN01e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def exercise_0(file):\n",
    "    pass\n",
    "\n",
    "def exercise_1(df):\n",
    "    pass\n",
    "\n",
    "def exercise_2(df, k):\n",
    "    pass\n",
    "\n",
    "def exercise_3(df, k):\n",
    "    pass\n",
    "\n",
    "def exercise_4(df):\n",
    "    pass\n",
    "\n",
    "def exercise_5(df):\n",
    "    pass\n",
    "\n",
    "def exercise_6(df):\n",
    "    pass\n",
    "\n",
    "def exercise_7(df):\n",
    "    pass\n",
    "\n",
    "def visual_1(df):\n",
    "    pass\n",
    "\n",
    "def visual_2(df):\n",
    "    pass\n",
    "\n",
    "def exercise_custom(df):\n",
    "    pass\n",
    "    \n",
    "def visual_custom(df):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "346fc3fc",
   "metadata": {
    "id": "346fc3fc"
   },
   "outputs": [],
   "source": [
    "df = exercise_0('transactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9158f0bd",
   "metadata": {
    "id": "9158f0bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['step', 'type', 'amount', 'nameOrig', 'oldbalanceOrg', 'newbalanceOrig', 'nameDest', 'oldbalanceDest', 'newbalanceDest', 'isFraud', 'isFlaggedFraud']\n",
      "Empty DataFrame\n",
      "Columns: [step, type, amount, nameOrig, oldbalanceOrg, newbalanceOrig, nameDest, oldbalanceDest, newbalanceDest, isFraud, isFlaggedFraud]\n",
      "Index: []\n",
      "           nameOrig  nameDest\n",
      "0        C745009740         2\n",
      "1        C260230637         2\n",
      "2         C44568807         2\n",
      "3       C1709295811         2\n",
      "4        C361604284         1\n",
      "...             ...       ...\n",
      "199991  C1648185402         1\n",
      "199992  C1648194899         1\n",
      "199993  C1648216508         1\n",
      "199994  C1648222711         1\n",
      "199995   C999983894         1\n",
      "\n",
      "[199996 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Test exercises here\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Read the dataset (`transactions.csv`) as a Pandas dataframe. Note that the first row of the CSV contains the column\n",
    "# names.\n",
    "def exercise_0(file):\n",
    "    df = pd.read_csv(file)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Return the column names as a list from the dataframe.\n",
    "def exercise_1(df):\n",
    "    columnNames = list(df.columns)\n",
    "    return columnNames\n",
    "\n",
    "\n",
    "# Return the first k rows from the dataframe.\n",
    "def exercise_2(df, k):\n",
    "    return df.head(k)\n",
    "\n",
    "\n",
    "# Return a random sample of k rows from the dataframe.\n",
    "def exercise_3(df, k):\n",
    "    return(df.sample(k))\n",
    "\n",
    "\n",
    "# Return a list of the unique transaction types.\n",
    "def exercise_4(df):\n",
    "    return df['type'].unique()\n",
    "\n",
    "\n",
    "# Return a Pandas series of the top 10 transaction destinations with frequencies.\n",
    "def exercise_5(df):\n",
    "    return df['nameDest'].value_counts().head(10)\n",
    "\n",
    "\n",
    "# Return all the rows from the dataframe for which fraud was detected.\n",
    "def exercise_6(df):\n",
    "    return df.loc[df['isFlaggedFraud'] == 1]\n",
    "\n",
    "\n",
    "# Bonus. Return a dataframe that contains the number of distinct destinations that each source has interacted with\n",
    "# to, sorted in descending order.\n",
    "def exercise_7(df):\n",
    "    data = df.groupby('nameOrig')['nameDest'].nunique().sort_values(ascending=False)\n",
    "    gk = pd.DataFrame(data).reset_index()\n",
    "    return gk\n",
    "\n",
    "\n",
    "def visual_1(df):\n",
    "    pass\n",
    "\n",
    "\n",
    "def visual_2(df):\n",
    "    pass\n",
    "\n",
    "\n",
    "def exercise_custom(df):\n",
    "    pass\n",
    "\n",
    "\n",
    "def visual_custom(df):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2dc2f4",
   "metadata": {
    "id": "ed2dc2f4"
   },
   "source": [
    "Create graphs for the following. \n",
    "1. Transaction types bar chart, Transaction types split by fraud bar chart\n",
    "1. Origin account balance delta v. Destination account balance delta scatter plot for Cash Out transactions\n",
    "\n",
    "Ensure that the graphs have the following:\n",
    " - Title\n",
    " - Labeled Axes\n",
    " \n",
    "The function plot the graph and then return a string containing a short description explaining the relevance of the chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab229b34",
   "metadata": {
    "id": "ab229b34"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def visual_1(df):\n",
    "    def transaction_counts(df):\n",
    "        return df.groupby('type').value_counts()\n",
    "\n",
    "    def transaction_counts_split_by_fraud(df):\n",
    "        return df['isFraud'].groupby('type')\n",
    "\n",
    "    fig, axs = plt.subplots(2, figsize=(6,10))\n",
    "    transaction_counts(df).plot(ax=axs[0], kind='bar')\n",
    "    axs[0].set_title('TODO')\n",
    "    axs[0].set_xlabel('TODO')\n",
    "    axs[0].set_ylabel('TODO')\n",
    "    transaction_counts_split_by_fraud(df).plot(ax=axs[1], kind='bar')\n",
    "    axs[1].set_title('TODO')\n",
    "    axs[1].set_xlabel('TODO')\n",
    "    axs[1].set_ylabel('TODO')\n",
    "    fig.suptitle('TODO')\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    for ax in axs:\n",
    "      for p in ax.patches:\n",
    "          ax.annotate(p.get_height(), (p.get_x(), p.get_height()))\n",
    "    return plt.show()\n",
    "\n",
    "visual_1(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ab2f47",
   "metadata": {
    "id": "38ab2f47"
   },
   "outputs": [],
   "source": [
    "def visual_2(df):\n",
    "    def query(df):\n",
    "        # TODO\n",
    "        pass\n",
    "    plot = query(df).plot.scatter(x='TODO',y='TODO')\n",
    "    plot.set_title('TODO')\n",
    "    plot.set_xlim(left=-1e3, right=1e3)\n",
    "    plot.set_ylim(bottom=-1e3, top=1e3)\n",
    "    return 'TODO'\n",
    "\n",
    "visual_2(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f572d06d",
   "metadata": {
    "id": "f572d06d"
   },
   "source": [
    "Use your newly-gained Pandas skills to find an insight from the dataset. You have full flexibility to go in whichever direction interests you. Please create a visual as above for this query. `visual_custom` should call `exercise_custom`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5393e5c5",
   "metadata": {
    "id": "5393e5c5"
   },
   "outputs": [],
   "source": [
    "def exercise_custom(df):\n",
    "    # TODO\n",
    "    pass\n",
    "    \n",
    "def visual_custom(df):\n",
    "    # TODO\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddecc786",
   "metadata": {
    "id": "ddecc786"
   },
   "source": [
    "Submission\n",
    "\n",
    "1. Copy the exercises into `task1.py`.\n",
    "2. Upload `task1.py` to Forage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qpIxC3xgQpOo",
   "metadata": {
    "id": "qpIxC3xgQpOo"
   },
   "source": [
    "All done!\n",
    "\n",
    "Your work will be instrumental for our team's continued success."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "task1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
